#!/bin/bash
conda activate opencompass-vllm
# qwen2.5-vl-7B
vllm serve /fs-computility/ai-shen/shared/hf-hub/models--Qwen--Qwen2.5-VL-7B-Instruct/snapshots/5b5eecc7efc2c3e86839993f2689bbbdf06bd8d4 --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --limit_mm_per_prompt image=10 --max_model_len 20000 --served-model-name Qwen2.5-VL-7B-Instruct
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_vl_7b_promptv7_T5_temp0.7-beta0.1_alpha0/global_step_162 --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --limit_mm_per_prompt image=10 --max_model_len 20000 --served-model-name Qwen2.5-VL-7B-Instruct
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_vl_7b_promptv7_T5_temp0.7-beta0.1_alpha1/global_step_162 --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --limit_mm_per_prompt image=10 --max_model_len 20000 --served-model-name Qwen2.5-VL-7B-Instruct
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_vl_7b_promptv7_T5_temp0.7-beta0.1_alpha0.5/global_step_162 --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --limit_mm_per_prompt image=10 --max_model_len 20000 --served-model-name Qwen2.5-VL-7B-Instruct
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_vl_7b_promptv7_T5_temp0.7-beta0.1_ece_we0.1_alpha0.5/global_step_162 --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --limit_mm_per_prompt image=10 --max_model_len 20000 --served-model-name Qwen2.5-VL-7B-Instruct
# multimodal Invalid training
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_vl_7b_promptv8_T5_temp0.7-multimodalInvalid-beta0_alpha0/global_step_181 --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --limit_mm_per_prompt image=10 --max_model_len 20000 --served-model-name Qwen2.5-VL-7B-Instruct
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_vl_7b_promptv8_T5_temp0.7-multimodalInvalid-beta0.1_alpha0/global_step_181 --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --limit_mm_per_prompt image=10 --max_model_len 20000 --served-model-name Qwen2.5-VL-7B-Instruct
# m3cot training
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_vl_7b_promptv8_T5_temp0.7-m3cot-beta0.1_alpha0.5/global_step_60 --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --limit_mm_per_prompt image=10 --max_model_len 20000 --served-model-name Qwen2.5-VL-7B-Instruct
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_vl_7b_promptv8_T5_temp0.7-m3cot-beta0.1_alpha0.1/global_step_60/actor --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --limit_mm_per_prompt image=10 --max_model_len 20000 --served-model-name Qwen2.5-VL-7B-Instruct
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_vl_7b_promptv8_T5_temp0.7-m3cot-beta0_alpha0/global_step_60 --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --limit_mm_per_prompt image=10 --max_model_len 20000 --served-model-name Qwen2.5-VL-7B-Instruct
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_vl_7b_promptv8_T5_temp0.7-m3cot-beta0.1_alpha0/global_step_60 --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --limit_mm_per_prompt image=10 --max_model_len 20000 --served-model-name Qwen2.5-VL-7B-Instruct
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_vl_7b_promptv8_T5_temp0.7-m3cot-beta0_alpha0.5_CURece_we0.1/global_step_60 --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --limit_mm_per_prompt image=10 --max_model_len 20000 --served-model-name Qwen2.5-VL-7B-Instruct
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_vl_7b_promptv8_T5_temp0.7-m3cot-beta0_alpha0.1_CURece_we0.1/global_step_60/actor --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --limit_mm_per_prompt image=10 --max_model_len 20000 --served-model-name Qwen2.5-VL-7B-Instruct
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_vl_7b_promptv8_T5_temp0.7-m3cot-beta0_alpha0.5_dynamicece_we0.1/global_step_60 --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --limit_mm_per_prompt image=10 --max_model_len 20000 --served-model-name Qwen2.5-VL-7B-Instruct
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_vl_7b_promptv8_T5_temp0.7-m3cot-beta0_alpha0.1_dynamicece_we0.1/global_step_60 --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --limit_mm_per_prompt image=10 --max_model_len 20000 --served-model-name Qwen2.5-VL-7B-Instruct
# text training
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_vl_7b_promptv8_T5_temp0.7-text-beta0_alpha0/global_step_103 --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --limit_mm_per_prompt image=10 --max_model_len 20000 --served-model-name Qwen2.5-VL-7B-Instruct
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_vl_7b_promptv8_T5_temp0.7-text-beta0.1_alpha0/global_step_103 --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --limit_mm_per_prompt image=10 --max_model_len 20000 --served-model-name Qwen2.5-VL-7B-Instruct
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_vl_7b_promptv8_T5_temp0.7-text-beta0.1_alpha0.5/global_step_103 --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --limit_mm_per_prompt image=10 --max_model_len 20000 --served-model-name Qwen2.5-VL-7B-Instruct
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_vl_7b_promptv8_T5_temp0.7-text-beta0_alpha0.5_CURece_we0.1/global_step_103 --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --limit_mm_per_prompt image=10 --max_model_len 20000 --served-model-name Qwen2.5-VL-7B-Instruct
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_vl_7b_promptv8_T5_temp0.7-text-beta0_alpha0_CURece_we0.1/global_step_103 --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --limit_mm_per_prompt image=10 --max_model_len 20000 --served-model-name Qwen2.5-VL-7B-Instruct
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_vl_7b_promptv8_T5_temp0.7-text-beta0.1_alpha0.1/global_step_103 --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --limit_mm_per_prompt image=10 --max_model_len 20000 --served-model-name Qwen2.5-VL-7B-Instruct
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_vl_7b_promptv8_T5_temp0.7-text-beta0_alpha0.1_CURece_we0.1/global_step_103 --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --limit_mm_per_prompt image=10 --max_model_len 20000 --served-model-name Qwen2.5-VL-7B-Instruct

# ablate beta
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_vl_7b_promptv8_T5_temp0.7-text-beta0.3_alpha0/global_step_103 --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --limit_mm_per_prompt image=10 --max_model_len 20000 --served-model-name Qwen2.5-VL-7B-Instruct
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_vl_7b_promptv8_T5_temp0.7-text-beta0.2_alpha0/global_step_103 --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --limit_mm_per_prompt image=10 --max_model_len 20000 --served-model-name Qwen2.5-VL-7B-Instruct
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_vl_7b_promptv8_T5_temp0.7-text-beta0.4_alpha0/global_step_103 --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --limit_mm_per_prompt image=10 --max_model_len 20000 --served-model-name Qwen2.5-VL-7B-Instruct
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_vl_7b_promptv8_T5_temp0.7-text-beta0.05_alpha0/global_step_103 --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --limit_mm_per_prompt image=10 --max_model_len 20000 --served-model-name Qwen2.5-VL-7B-Instruct

# ablate alpha
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_vl_7b_promptv8_T5_temp0.7-text-beta0.1_alpha0.1/global_step_103 --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --limit_mm_per_prompt image=10 --max_model_len 20000 --served-model-name Qwen2.5-VL-7B-Instruct
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_vl_7b_promptv8_T5_temp0.7-text-beta0.1_alpha0.3/global_step_103 --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --limit_mm_per_prompt image=10 --max_model_len 20000 --served-model-name Qwen2.5-VL-7B-Instruct
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_vl_7b_promptv8_T5_temp0.7-text-beta0.1_alpha0.7/global_step_103 --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --limit_mm_per_prompt image=10 --max_model_len 20000 --served-model-name Qwen2.5-VL-7B-Instruct
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_vl_7b_promptv8_T5_temp0.7-text-beta0.1_alpha0.9/global_step_103 --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --limit_mm_per_prompt image=10 --max_model_len 20000 --served-model-name Qwen2.5-VL-7B-Instruct

# ablate data proportion
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_vl_7b_promptv8_T5_temp0.7-textRandom-beta0.1_alpha0.5/global_step_116 --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --limit_mm_per_prompt image=10 --max_model_len 20000 --served-model-name Qwen2.5-VL-7B-Instruct
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_vl_7b_promptv8_T5_temp0.7-textProportion-beta0.1_alpha0.5/global_step_116 --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --limit_mm_per_prompt image=10 --max_model_len 20000 --served-model-name Qwen2.5-VL-7B-Instruct
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_vl_7b_promptv8_T5_temp0.7-textBalance-beta0.1_alpha0.5/global_step_116 --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --limit_mm_per_prompt image=10 --max_model_len 20000 --served-model-name Qwen2.5-VL-7B-Instruct

# qwen2.5-7B
vllm serve /fs-computility/ai-shen/shared/hf-hub/models--Qwen--Qwen2.5-7B-Instruct --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9  --max_model_len 20000 --served-model-name Qwen2.5-7B-Instruct
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_7b_c2rm-ece_w0.1_alpha0.5_step_162 --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9  --max_model_len 20000 --served-model-name Qwen2.5-7B-Instruct
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_7b_c2rm-beta0.1_alpha0_step_162 --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9  --max_model_len 20000 --served-model-name Qwen2.5-7B-Instruct
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_7b_c2rm-ece_we0.1_wd1_window100_alpha0_step_162 --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9  --max_model_len 20000 --served-model-name Qwen2.5-7B-Instruct
vllm serve /fs-computility/wangxuhong/yangxuqing/verl/merged_model/qwen2_5_7b_c2rm-ece_we0.1_wd1_window100_alpha1_step_162 --dtype half --port 8007 --tensor-parallel-size 2 --gpu-memory-utilization 0.9  --max_model_len 20000 --served-model-name Qwen2.5-7B-Instruct

# qwen2.5-vl-32B
export CUDA_VISIBLE_DEVICES=2,3
vllm serve /fs-computility/ai-shen/shared/hf-hub/models--Qwen--Qwen2.5-VL-32B-Instruct/snapshots/7cfb30d71a1f4f49a57592323337a4a4727301da --dtype half --port 8032 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --limit_mm_per_prompt image=10 --max_model_len 20000 --served-model-name Qwen2.5-VL-32B-Instruct

# qwen2.5-vl-72B
export CUDA_VISIBLE_DEVICES=4,5,6,7
vllm serve /fs-computility/ai-shen/shared/hf-hub/models--Qwen--Qwen2.5-VL-72B-Instruct/snapshots/5d8e171e5ee60e8ca4c6daa380bd29f78fe19021 --dtype half --port 8072 --tensor-parallel-size 4 --gpu-memory-utilization 0.9 --limit_mm_per_prompt image=10 --max_model_len 20000 --served-model-name Qwen2.5-VL-72B-Instruct

# qwen3-32B
export CUDA_VISIBLE_DEVICES=2,3
vllm serve /fs-computility/ai-shen/shared/hf-hub/Qwen3-32B/ --dtype half --port 8332 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --max_model_len 20000 --served-model-name Qwen3-32B
# qwen3-32B-non-thinking
vllm serve /fs-computility/ai-shen/shared/hf-hub/Qwen3-32B/ --dtype half --port 8432 --tensor-parallel-size 2 --gpu-memory-utilization 0.9 --max_model_len 20000 --served-model-name Qwen3-32B-non-thinking